{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore 'dask' warning\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "from pandas import DataFrame\n",
    "from IPython.display import HTML\n",
    "from google.cloud.storage import Blob\n",
    "import datalab.storage as gcs_datalab\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up constants. All required\n",
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing bucket\n",
    "fs = gcsfs.GCSFileSystem(project='graydon-moving-indicator')\n",
    "gcs = storage.Client()\n",
    "bucket = gcs.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['date_month', 'id_company', 'id_branch',\n",
    "       'is_discontinued',\n",
    "       'financial_calamity_outcome', 'date_established', \n",
    "       'qty_employees', 'year_qty_employees', 'id_company_creditproxy',\n",
    "       'score_payment_assessment', 'amt_revenue',\n",
    "       'year_revenue', 'amt_consolidated_revenue', 'year_consolidated_revenue',\n",
    "       'amt_consolidated_operating_result',\n",
    "       'year_consolidated_operating_result', \n",
    "       'perc_credit_limit_adjustment', 'color_credit_status', 'rat_pd',\n",
    "       'score_pd','has_increased_risk',\n",
    "       'is_sole_proprietor', 'code_SBI_2', 'code_SBI_1',\n",
    "       'qty_address_mutations_total',\n",
    "       'qty_address_mutations_month', \n",
    "       'has_relocated',\n",
    "       'has_name_change', 'code_discontinuation', 'code_financial_calamity',\n",
    "       'qty_issued_credit_reports', 'Associate', 'Authorized official', 'Board member', 'Chairman',\n",
    "       'Commissioner', 'Director', 'Liquidator', 'Major', 'Managing clerk',\n",
    "       'Managing partner', 'Member of the partnership', 'Miscellaneous',\n",
    "       'Owner', 'Secretary', 'Secretary/Treasurer', 'Treasurer', 'Unknown',\n",
    "       'Vice President', 'amt_operating_result', 'code_legal_form', 'date_financial_calamity_started', \n",
    "       'date_financial_calamity_stopped', 'date_start', 'from_date_start',\n",
    "       'qty_stopped_names', 'qty_started_names', 'year_operating_result'       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_board_members(df):\n",
    "    \"\"\"Agregates the number of board members into one feature \"\"\"    \n",
    "    col_list_to_sum = ['associate', 'authorized_official', 'board_member', 'chairman', 'commissioner',\n",
    "       'director', 'liquidator', 'major', 'managing_clerk', 'managing_partner',\n",
    "       'member_of_the_partnership', 'miscellaneous', 'owner', 'secretary',\n",
    "       'secretary/treasurer', 'treasurer', 'unknown', 'vice_president']  \n",
    "    df['total_changeof_board_members_'] = df[col_list_to_sum].sum(axis=1)\n",
    "    df = df.drop(columns=col_list_to_sum)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_one_month_csv_from_bucket(year, month, last_day_of_month, dir_prefix = '', selected_columns= ''):\n",
    "    \"\"\" Reads one month of data and returns a pandas Df \"\"\"\n",
    "    one_month_df = pd.DataFrame()\n",
    "    dir_prefix = dir_prefix + '/' + year\n",
    "    print(dir_prefix)\n",
    "    blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "    for blob in blob_list:\n",
    "        if month + '-' + last_day_of_month in blob.name:\n",
    "            print('Processing file: ', blob.name)\n",
    "            with fs.open('graydon-data/' + blob.name) as f:\n",
    "                if selected_columns == '' or None:\n",
    "                    one_month_df = pd.read_csv(f, sep=';')\n",
    "                else:\n",
    "                    one_month_df = pd.read_csv(f, sep=';', usecols= selected_columns)\n",
    "    one_month_df.columns = (one_month_df.columns.str.strip().str.lower().str.replace(' ', '_').\n",
    "                            str.replace('(', '').str.replace(')', '') )\n",
    "    return one_month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "def read_all_csv_months_yearly_from_bucket_merged(years_to_read_in_list, dir_prefix = '', selected_columns = ''):\n",
    "    \"\"\" Reads a whole year of data and returns a monthly merged pandas Df \"\"\"\n",
    "    all_years_merged_df = pd.DataFrame()\n",
    "    for year in years_to_read_in_list:\n",
    "        print('Starting with year: ', year)\n",
    "        dir_prefix = dir_prefix + '/' + year\n",
    "        blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "        for blob in blob_list:  \n",
    "            one_month_df = None\n",
    "            if 'CSV' in blob.name:\n",
    "                print('Processing file: ', blob.name)\n",
    "                with fs.open('graydon-data/' + blob.name) as f:\n",
    "                    one_month_df = pd.read_csv(f, sep=';', usecols= selected_columns)   \n",
    "                    one_month_df = one_month_df[(one_month_df['is_sole_proprietor'] == 0) ]\n",
    "                                               # & (one_month_df['is_discontinued'] == 0) \n",
    "                    one_month_df.columns = (one_month_df.columns.str.strip().str.lower(). \n",
    "                    str.replace(' ', '_').str.replace('(', '').str.replace(')', '') )\n",
    "                    one_month_df = aggregate_board_members(one_month_df)\n",
    "                    one_month_df = clean_data_per_year(one_month_df)\n",
    "                    all_years_merged_df = all_years_merged_df.append(one_month_df)\n",
    "            print('The number of rows so far is: ', all_years_merged_df.shape[0])\n",
    "    return all_years_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_data_per_year(df):\n",
    "    \"\"\"Cleans data and returns formatted df\"\"\"\n",
    "    df['date_month'] = pd.to_datetime(df['date_month'])\n",
    "    df['financial_calamity_outcome'] = df['financial_calamity_outcome'].fillna(-1) \n",
    "    df['qty_employees'] = df['qty_employees'].str.strip() \n",
    "    df.loc[df.qty_employees == 'NA', 'qty_employees'] = np.NaN\n",
    "    #df['qty_employees'] = df['qty_employees'].fillna(0) \n",
    "    #df['qty_employees'] = df['qty_employees'].astype(str).astype(int)\n",
    "    df['year_qty_employees'] = df['year_qty_employees'].str.strip()\n",
    "    df.loc[df.year_qty_employees == 'NA', 'year_qty_employees'] =  np.NaN\n",
    "    df['amt_revenue'] = df['amt_revenue'].str.strip() \n",
    "    df.loc[df.amt_revenue == 'NA', 'amt_revenue'] =  np.NaN\n",
    "    df['amt_revenue'] = df['amt_revenue'].astype(str).str.replace(',','.')\n",
    "    df['year_revenue'] = df['year_revenue'].str.strip() \n",
    "    df.loc[df.year_revenue == 'NA', 'year_revenue'] = 0\n",
    "    df['amt_consolidated_revenue'] = df['amt_consolidated_revenue'].str.strip() \n",
    "    df.loc[df.amt_consolidated_revenue == 'NA', 'amt_consolidated_revenue'] =  np.NaN\n",
    "    df['amt_consolidated_revenue'] = df['amt_consolidated_revenue'].astype(str).str.replace(',','.')\n",
    "    df['year_consolidated_revenue'] = df['year_consolidated_revenue'].str.strip() \n",
    "    df.loc[df.year_consolidated_revenue == 'NA', 'year_consolidated_revenue'] =  np.NaN\n",
    "    df['amt_consolidated_operating_result'] = df['amt_consolidated_operating_result'].str.strip() \n",
    "    df.loc[df.amt_consolidated_operating_result == 'NA', 'amt_consolidated_operating_result'] =  np.NaN\n",
    "    df['amt_consolidated_operating_result'] = df['amt_consolidated_operating_result'].astype(str).str.replace(',','.')\n",
    "    df['year_consolidated_operating_result'] = df['year_consolidated_operating_result'].str.strip() \n",
    "    df.loc[df.year_consolidated_operating_result == 'NA', 'year_consolidated_operating_result'] =  np.NaN\n",
    "    df['score_pd'] = df['score_pd'].str.strip() \n",
    "    df.loc[df.score_pd == 'NA', 'score_pd'] =  np.NaN\n",
    "    df['score_pd'] = df['score_pd'].astype(str).str.replace(',','.')\n",
    "    df['has_increased_risk'] = df['has_increased_risk'].astype(bool)\n",
    "    #df.loc[df.has_increased_risk == None, 'has_increased_risk'] = False\n",
    "    #df.loc[df.code_sbi_2.isnull(), 'code_sbi_2'] = 0  \n",
    "    df.loc[df.date_established < '1700-12-31' , 'date_established'] =  np.NaN\n",
    "    df['date_established'] = pd.to_datetime(df['date_established'])\n",
    "    df['amt_operating_result'] = df['amt_operating_result'].str.strip() \n",
    "    df.loc[df.amt_operating_result == 'NA', 'amt_operating_result'] =  np.NaN\n",
    "    df['amt_operating_result'] = df['amt_operating_result'].astype(str).str.replace(',','.')\n",
    "    df['year_operating_result'] = df['year_consolidated_operating_result'].str.strip() \n",
    "    df.loc[df.year_operating_result == 'NA', 'year_operating_result'] =  np.NaN\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df_locally(df, dir_prefix, year, as_json= False):\n",
    "    \"\"\" Saves df as json or csv locally on server \"\"\"\n",
    "    if as_json:        \n",
    "        file_path = dir_prefix + '/' + year + '_merged_cleaned.json'\n",
    "        df.to_json(file_path)\n",
    "    else:\n",
    "        file_path =  dir_prefix + '/' + year + '_merged_cleaned.csv'\n",
    "        df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading one year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with year:  2018\n",
      "Processing file:  01_input/2018/modelling_2018-01-01_2018-01-31.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/IPython/core/magic.py:187: DtypeWarning: Columns (20,46,58,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  call = lambda f, *a, **k: f(*a, **k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far is:  579524\n",
      "Processing file:  01_input/2018/modelling_2018-02-01_2018-02-28.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/IPython/core/magic.py:187: DtypeWarning: Columns (6,9,10,11,16,17,20,35,36,37,43,44,46,51,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  call = lambda f, *a, **k: f(*a, **k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far is:  2493537\n",
      "Processing file:  01_input/2018/modelling_2018-03-01_2018-03-31.CSV\n",
      "The number of rows so far is:  4411795\n",
      "Processing file:  01_input/2018/modelling_2018-04-01_2018-04-30.CSV\n",
      "The number of rows so far is:  6335918\n",
      "Processing file:  01_input/2018/modelling_2018-05-01_2018-05-31.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/IPython/core/magic.py:187: DtypeWarning: Columns (6,9,10,11,16,17,20,35,43,44,46,51,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  call = lambda f, *a, **k: f(*a, **k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far is:  8264530\n",
      "Processing file:  01_input/2018/modelling_2018-06-01_2018-06-30.CSV\n",
      "The number of rows so far is:  10196724\n",
      "Processing file:  01_input/2018/modelling_2018-07-01_2018-07-31.CSV\n",
      "The number of rows so far is:  12135976\n",
      "Processing file:  01_input/2018/modelling_2018-08-01_2018-08-31.CSV\n",
      "The number of rows so far is:  14080404\n",
      "Processing file:  01_input/2018/modelling_2018-09-01_2018-09-30.CSV\n",
      "The number of rows so far is:  16028664\n",
      "Processing file:  01_input/2018/modelling_2018-10-01_2018-10-31.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/IPython/core/magic.py:187: DtypeWarning: Columns (9,10,11,16,17,20,43,46,51,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  call = lambda f, *a, **k: f(*a, **k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far is:  17983504\n",
      "CPU times: user 13min 28s, sys: 2min 10s, total: 15min 38s\n",
      "Wall time: 41min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_one_year = read_all_csv_months_yearly_from_bucket_merged(dir_prefix ='01_input', \n",
    "                                                              selected_columns= selected_columns\n",
    "                                                              ,years_to_read_in_list=['2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview of the data \n",
    "HTML(DataFrame(df_one_year).head(20).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Displaying number of rows and columns\n",
    "df_one_year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving df locally\n",
    "save_df_locally(df= df_one_year, dir_prefix= 'files_to_bucket', year= '2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
