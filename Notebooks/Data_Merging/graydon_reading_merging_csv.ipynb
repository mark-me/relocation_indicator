{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading csv graydon data from buckets\n",
    "#### Merging csv monthly files into yearly files\n",
    "#### Uploading yearly files to Google Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ignore 'dask' warning\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "from pandas import DataFrame\n",
    "from IPython.display import HTML\n",
    "from google.cloud.storage import Blob\n",
    "import datalab.storage as gcs_datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up constants. All required\n",
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing bucket\n",
    "fs = gcsfs.GCSFileSystem(project='graydon-moving-indicator')\n",
    "gcs = storage.Client()\n",
    "bucket = gcs.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['date_month', 'id_company', 'id_branch',\n",
    "       'is_discontinued',\n",
    "       'financial_calamity_outcome',\n",
    "       'qty_employees', 'year_qty_employees', 'id_company_creditproxy',\n",
    "       'score_payment_assessment', 'amt_revenue',\n",
    "       'year_revenue', 'amt_consolidated_revenue', 'year_consolidated_revenue',\n",
    "       'amt_consolidated_operating_result',\n",
    "       'year_consolidated_operating_result', \n",
    "       'perc_credit_limit_adjustment', 'color_credit_status', 'rat_pd',\n",
    "       'score_pd','has_increased_risk',\n",
    "       'is_sole_proprietor', 'code_SBI_2', 'code_SBI_1',\n",
    "       'qty_address_mutations_total',\n",
    "       'qty_address_mutations_month', \n",
    "       'has_relocated',\n",
    "       'has_name_change',  'Vice President'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns_small = ['date_month', 'id_company', 'id_branch', 'date_established',\n",
    "       'is_discontinued',\n",
    "       'financial_calamity_outcome',\n",
    "       'qty_employees', 'year_qty_employees', 'id_company_creditproxy',\n",
    "       'score_payment_assessment', 'amt_revenue',\n",
    "       'year_revenue', 'amt_consolidated_revenue', 'year_consolidated_revenue',\n",
    "       'perc_credit_limit_adjustment', 'color_credit_status', 'rat_pd',\n",
    "       'score_pd','has_increased_risk',\n",
    "       'is_sole_proprietor', 'code_SBI_2', 'code_SBI_1', 'qty_address_mutations_total',\n",
    "       'qty_address_mutations_month', 'has_relocated',\n",
    "        'has_name_change'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "def read_all_csv_months_yearly_from_bucket(years_to_read_in_list, dir_prefix = '', selected_columns = ''):\n",
    "    \"\"\" Reads a whole year of data and returns a dictionary with year \n",
    "        number as key and a list of monthly pandas dfs  \n",
    "    \"\"\"\n",
    "    all_years_dict = {}\n",
    "    for year in years_to_read_in_list:\n",
    "        print('Starting with year: ', year)\n",
    "        dir_prefix = dir_prefix + '/' + year\n",
    "        one_year_csvs = []\n",
    "        blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "        for blob in blob_list:  \n",
    "            one_month_df = None\n",
    "            if 'CSV' in blob.name:\n",
    "                print('Processing file: ', blob.name)\n",
    "                with fs.open('graydon-data/' + blob.name) as f:\n",
    "                    one_month_df = pd.read_csv(f, sep=';', usecols= selected_columns)   \n",
    "                    one_year_csvs.append(one_month_df)      \n",
    "        all_years_dict[year] = one_year_csvs\n",
    "    return all_years_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "def read_all_csv_months_yearly_from_bucket_merged(years_to_read_in_list, dir_prefix = '', selected_columns = ''):\n",
    "    \"\"\" Reads a whole year of data and returns a monthly merged pandas Df \"\"\"\n",
    "    all_years_merged_df = pd.DataFrame()\n",
    "    for year in years_to_read_in_list:\n",
    "        print('Starting with year: ', year)\n",
    "        dir_prefix = dir_prefix + '/' + year\n",
    "        blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "        for blob in blob_list:  \n",
    "            one_month_df = None\n",
    "            if 'CSV' in blob.name:\n",
    "                print('Processing file: ', blob.name)\n",
    "                with fs.open('graydon-data/' + blob.name) as f:\n",
    "                    one_month_df = pd.read_csv(f, sep=';', usecols= selected_columns)   \n",
    "                    one_month_df = one_month_df[(one_month_df['is_sole_proprietor'] == 0) ]\n",
    "                                               # & (one_month_df['is_discontinued'] == 0) \n",
    "                    one_month_df.columns = (one_month_df.columns.str.strip().str.lower(). \n",
    "                    str.replace(' ', '_').str.replace('(', '').str.replace(')', '') )\n",
    "                    all_years_merged_df = all_years_merged_df.append(one_month_df)\n",
    "            print('The number of rows so far is: ', all_years_merged_df.shape[0])\n",
    "    return all_years_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_one_month_csv_from_bucket(year, month, last_day_of_month, dir_prefix = '', selected_columns= ''):\n",
    "    \"\"\" Reads one month of data and returns a pandas Df \"\"\"\n",
    "    one_month_df = pd.DataFrame()\n",
    "    dir_prefix = dir_prefix + '/' + year\n",
    "    print(dir_prefix)\n",
    "    blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "    for blob in blob_list:\n",
    "        if month + '-' + last_day_of_month in blob.name:\n",
    "            print('Processing file: ', blob.name)\n",
    "            with fs.open('graydon-data/' + blob.name) as f:\n",
    "                if selected_columns == '' or None:\n",
    "                    one_month_df = pd.read_csv(f, sep=';')\n",
    "                else:\n",
    "                    one_month_df = pd.read_csv(f, sep=';', usecols= selected_columns)\n",
    "    one_month_df.columns = (one_month_df.columns.str.strip().str.lower(). \n",
    "                    str.replace(' ', '_').str.replace('(', '').str.replace(')', '') )\n",
    "    return one_month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upload_df_to_gc_bucket(df, dir_prefix, year, as_json= False):\n",
    "    \"\"\" Uploads pandas DF to Gc bucket either as json or csv \"\"\"\n",
    "    if as_json:\n",
    "        df_json = df.to_json()\n",
    "        new_file_path = dir_prefix + '/' + year + '_merged.json'\n",
    "        gcs_datalab.Bucket(bucket_name).item(new_file_path).write_to(df_json,'text/json')\n",
    "    else:\n",
    "        df_csv = df.to_csv()\n",
    "        new_file_path = dir_prefix + '/' + year + '_merged.csv'\n",
    "        gcs_datalab.Bucket(bucket_name).item(new_file_path).write_to(df_csv,'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jan_2017_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jan_2017_df = read_one_month_csv_from_bucket(year= '2017', month= '01', \n",
    "                                             last_day_of_month= '31', dir_prefix ='including_scores/unzipped' , \n",
    "                                             selected_columns= selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Read one month all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jan_2017_df_all_columns = read_one_month_csv_from_bucket(year= '2017', month= '01', \n",
    "                                             last_day_of_month= '31', dir_prefix ='including_scores/unzipped' , \n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Read one full year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with year:  2018\n",
      "The number of rows so far is:  0\n",
      "Processing file:  including_scores/unzipped/2018/modelling_2018-01-01_2018-01-31.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (6,16,17,20,35,36,37,43,44,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far is:  1907886\n",
      "Processing file:  including_scores/unzipped/2018/modelling_2018-02-01_2018-02-28.CSV\n",
      "The number of rows so far is:  3821899\n",
      "Processing file:  including_scores/unzipped/2018/modelling_2018-03-01_2018-03-31.CSV\n"
     ]
    }
   ],
   "source": [
    "one_year_df = read_all_csv_months_yearly_from_bucket_merged(dir_prefix='including_scores/unzipped', \n",
    "                                                            years_to_read_in_list= ['2018'], \n",
    "                                                            selected_columns= selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload df to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upload_df_to_gc_bucket(df= jan_2017_df, dir_prefix='including_scores/merged_per_year', year= '2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(DataFrame(one_year_df.head(20)).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_df_to_bucket(df= one_year_df, dir_prefix='including_scores/merged_per_year', year= '2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
