{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore 'dask' warning\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "from pandas import DataFrame\n",
    "from IPython.display import HTML\n",
    "from google.cloud.storage import Blob\n",
    "import datalab.storage as gcs_datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up constants. All required\n",
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing bucket\n",
    "fs = gcsfs.GCSFileSystem(project='graydon-moving-indicator')\n",
    "gcs = storage.Client()\n",
    "bucket = gcs.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['date_month', 'id_company', 'id_branch',\n",
    "       'is_discontinued',\n",
    "       'financial_calamity_outcome', 'date_established', \n",
    "       'qty_employees', 'year_qty_employees', 'id_company_creditproxy',\n",
    "       'score_payment_assessment', 'amt_revenue',\n",
    "       'year_revenue', 'amt_consolidated_revenue', 'year_consolidated_revenue',\n",
    "       'amt_consolidated_operating_result',\n",
    "       'year_consolidated_operating_result', \n",
    "       'perc_credit_limit_adjustment', 'color_credit_status', 'rat_pd',\n",
    "       'score_pd','has_increased_risk',\n",
    "       'is_sole_proprietor', 'code_SBI_2', 'code_SBI_1',\n",
    "       'qty_address_mutations_total',\n",
    "       'qty_address_mutations_month', \n",
    "       'has_relocated',\n",
    "       'has_name_change',  'Vice President'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "def read_all_csv_months_yearly_from_bucket_merged(years_to_read_in_list, dir_prefix = '', selected_columns = ''):\n",
    "    \"\"\" Reads a whole year of data and returns a monthly merged pandas Df \"\"\"\n",
    "    all_years_merged_df = pd.DataFrame()\n",
    "    for year in years_to_read_in_list:\n",
    "        print('Starting with year: ', year)\n",
    "        dir_prefix = dir_prefix + '/' + year\n",
    "        blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "        for blob in blob_list:  \n",
    "            one_month_df = None\n",
    "            if 'CSV' in blob.name:\n",
    "                print('Processing file: ', blob.name)\n",
    "                with fs.open('graydon-data/' + blob.name) as f:\n",
    "                    one_month_df = pd.read_csv(f, sep=';', usecols= selected_columns)   \n",
    "                    one_month_df = one_month_df[(one_month_df['is_sole_proprietor'] == 0) ]\n",
    "                                               # & (one_month_df['is_discontinued'] == 0) \n",
    "                    one_month_df.columns = (one_month_df.columns.str.strip().str.lower(). \n",
    "                    str.replace(' ', '_').str.replace('(', '').str.replace(')', '') )\n",
    "                    all_years_merged_df = all_years_merged_df.append(one_month_df)\n",
    "            print('The number of rows so far is: ', all_years_merged_df.shape[0])\n",
    "    return all_years_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data_per_year(df):\n",
    "    df['date_month'] = pd.to_datetime(df['date_month'])\n",
    "    df['financial_calamity_outcome'] = df['financial_calamity_outcome'].fillna(-1) \n",
    "    df['qty_employees'] = df['qty_employees'].str.strip() \n",
    "    df.loc[df.qty_employees == 'NA', 'qty_employees'] = 0\n",
    "    df['qty_employees'] = df['qty_employees'].fillna(0) \n",
    "    df['qty_employees'] = df['qty_employees'].astype(str).astype(int)\n",
    "    df['year_qty_employees'] = df['year_qty_employees'].str.strip()\n",
    "    df.loc[df.year_qty_employees == 'NA', 'year_qty_employees'] = None\n",
    "    df['amt_revenue'] = df['amt_revenue'].str.strip() \n",
    "    df.loc[df.amt_revenue == 'NA', 'amt_revenue'] = 0\n",
    "    df['amt_revenue'] = df['amt_revenue'].astype(str).str.replace(',','.').astype(float)\n",
    "    df['year_revenue'] = df['year_revenue'].str.strip() \n",
    "    df.loc[df.year_revenue == 'NA', 'year_revenue'] = 0\n",
    "    df['amt_consolidated_revenue'] = df['amt_consolidated_revenue'].str.strip() \n",
    "    df.loc[df.amt_consolidated_revenue == 'NA', 'amt_consolidated_revenue'] = 0\n",
    "    df['amt_consolidated_revenue'] = df['amt_consolidated_revenue'].astype(str).str.replace(',','.').astype(float)\n",
    "    df['year_consolidated_revenue'] = df['year_consolidated_revenue'].str.strip() \n",
    "    df.loc[df.year_consolidated_revenue == 'NA', 'year_consolidated_revenue'] = 0\n",
    "    df['amt_consolidated_operating_result'] = df['amt_consolidated_operating_result'].str.strip() \n",
    "    df.loc[df.amt_consolidated_operating_result == 'NA', 'amt_consolidated_operating_result'] = 0\n",
    "    df['amt_consolidated_operating_result'] = df['amt_consolidated_operating_result'].astype(str).str.replace(',','.').astype(float)\n",
    "    df['year_consolidated_operating_result'] = df['year_consolidated_operating_result'].str.strip() \n",
    "    df.loc[df.year_consolidated_operating_result == 'NA', 'year_consolidated_operating_result'] = 0\n",
    "    df['score_pd'] = df['score_pd'].str.strip() \n",
    "    df.loc[df.score_pd == 'NA', 'score_pd'] = 0\n",
    "    df['score_pd'] = df['score_pd'].astype(str).str.replace(',','.').astype(float)\n",
    "    df['has_increased_risk'] = df['has_increased_risk'].astype(bool)\n",
    "    df.loc[df.has_increased_risk == None, 'has_increased_risk'] = False\n",
    "    df.loc[df.code_sbi_2.isnull(), 'code_sbi_2'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df_locally(df, dir_prefix, year, as_json= False):\n",
    "    \"\"\" Saves df as json or csv locally on server \"\"\"\n",
    "    if as_json:        \n",
    "        file_path = dir_prefix + '/' + year + '_merged.json'\n",
    "        df.to_json(file_path)\n",
    "    else:\n",
    "        file_path =  dir_prefix + '/' + year + '_merged.csv'\n",
    "        df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading one year by using the montly files and merging them to one year df\n",
    "df_one_year = read_all_csv_months_yearly_from_bucket_merged(dir_prefix='including_scores/unzipped', \n",
    "                                                            years_to_read_in_list= ['2018'], \n",
    "                                                            selected_columns= selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning \n",
    "df_one_year = clean_data_per_year(df_one_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving df locally\n",
    "save_df_locally(df= one_year_df, dir_prefix= 'files_to_bucket', year= '2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
