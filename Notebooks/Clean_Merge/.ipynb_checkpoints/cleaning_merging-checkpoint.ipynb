{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cleaning_merging import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore 'dask' warning\n",
    "from datetime import datetime\n",
    "#from pandas import DataFrame\n",
    "from IPython.display import HTML\n",
    "#from google.cloud.storage import Blob\n",
    "#import datalab.storage as gcs_datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_dataset = datetime.strptime(\"2018-01-01\", '%Y-%m-%d')\n",
    "columns_targets = ['date_month', 'id_company', 'id_branch', 'is_sole_proprietor', 'has_relocated']\n",
    "columns_features = ['date_month', 'id_company', 'id_branch',\n",
    "                    'is_discontinued', 'financial_calamity_outcome', 'date_established', 'qty_employees', \n",
    "                    'year_qty_employees', 'id_company_creditproxy', 'score_payment_assessment', \n",
    "                    'amt_revenue', 'year_revenue', 'amt_consolidated_revenue', 'year_consolidated_revenue',\n",
    "                    'amt_consolidated_operating_result', 'year_consolidated_operating_result', \n",
    "                    'perc_credit_limit_adjustment', 'color_credit_status', 'rat_pd', 'score_pd',\n",
    "                    'has_increased_risk', 'is_sole_proprietor', 'code_SBI_2', 'code_SBI_1',\n",
    "                    'qty_address_mutations_total', 'qty_address_mutations_month', 'has_name_change', \n",
    "                    'code_discontinuation', 'code_financial_calamity', 'qty_issued_credit_reports', \n",
    "                    'Associate', 'Authorized official', 'Board member', 'Chairman', 'Commissioner', \n",
    "                    'Director', 'Liquidator', 'Major', 'Managing clerk', 'Managing partner', \n",
    "                    'Member of the partnership', 'Miscellaneous', 'Owner', 'Secretary', 'Secretary/Treasurer', \n",
    "                    'Treasurer', 'Unknown', 'Vice President', 'amt_operating_result', 'code_legal_form', \n",
    "                    'date_financial_calamity_started', 'date_financial_calamity_stopped', 'date_start', \n",
    "                    'from_date_start', 'qty_stopped_names', 'qty_started_names', 'year_operating_result']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up constants. All required\n",
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'\n",
    "dir_input_data = '01_input'\n",
    "clean_merge = Cleaner_Merger(project, bucket_name, dir_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 01_input/2017/modelling_2017-01-01_2017-01-31.CSV with 5000 rows\n",
      "After removing sole proprietors there are 4411 rows are left\n",
      "The number of rows so far by adding 01_input/2017/modelling_2017-01-01_2017-01-31.CSV : 4411\n",
      "Read 01_input/2017/modelling_2017-02-01_2017-02-28.CSV with 5000 rows\n",
      "After removing sole proprietors there are 4412 rows are left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far by adding 01_input/2017/modelling_2017-02-01_2017-02-28.CSV : 8823\n"
     ]
    }
   ],
   "source": [
    "df_features = clean_merge.get_features(date_dataset, columns_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = clean_merge.add_previous_relocation_dates(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_relocation_dates = clean_merge.get_relocation_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_branch_months = df_features[['id_company', 'id_branch', 'date_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_branch_months = df_branch_months.merge(df_relocation_dates, \n",
    "                                          on=['id_company', 'id_branch'], \n",
    "                                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_branch_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_branch_months = df_branch_months[df_branch_months['date_month'] > df_branch_months['date_relocation_last']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_max_dates = df_branch_months.groupby(['id_company', 'id_branch', 'date_month'])['date_relocation_last', 'date_relocation_penultimate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features_news = df_features.merge(df_max_dates,\n",
    "                                      on=['id_company', 'id_branch', 'date_month'], \n",
    "                                      how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features_news['years_relocation_last'] = (df_features_news.date_month - df_features_news.date_relocation_last)/np.timedelta64(1, 'Y')\n",
    "df_features_news['years_relocation_penultimate'] = (df_features_news.date_month - df_features_news.date_relocation_penultimate)/np.timedelta64(1, 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_month = date_dataset\n",
    "\n",
    "df_months_combined = pd.DataFrame()  # The data frame which will contain all independent variables\n",
    "    \n",
    "# Get all months in range\n",
    "df_date_months = pd.DataFrame(pd.date_range(date_month, periods=12, freq=\"M\").tolist(),\n",
    "                              columns=['date_month'])\n",
    "df_date_months['date_month'] = df_date_months['date_month'].values.astype('datetime64[M]') # First day of month\n",
    "\n",
    "# Get the file names of all required month files\n",
    "#month_files = get_month_filenames(df_date_months, bucket, dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_files = [] # List of month files\n",
    "\n",
    "df_date_months['year'] = df_date_months.date_month.dt.year\n",
    "list_years = df_date_months['year'].unique()\n",
    "# If there are multiple years, iterate through years  \n",
    "for year in list_years:\n",
    "    # Get the year's data file names\n",
    "    dir_data_year = dir_data + '/' + str(year)\n",
    "    list_blob = list(bucket.list_blobs(prefix=dir_data_year))\n",
    "    # finding out which month files should be processed by looking which contain the first month date (YYYY-mm-01)\n",
    "    df_year_months = df_date_months[df_date_months['year'] == year]['date_month']\n",
    "    for blob in list_blob:\n",
    "        for month in df_year_months:\n",
    "            if (month.strftime(\"%Y-%m-%d\") in blob.name) & ('CSV' in blob.name):\n",
    "                month_files.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleaning, transforming and combining month files                \n",
    "for month_file in month_files:\n",
    "    with fs.open('graydon-data/' + month_file) as f:\n",
    "        df_month = pd.read_csv(f, sep=';', usecols= columns_features, index_col=False)   \n",
    "        df_month = df_month[(df_month['is_sole_proprietor'] == 0)] # & (one_month_df['is_discontinued'] == 0) \n",
    "        df_month.columns = (df_month.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', ''))\n",
    "        df_months_combined = df_months_combined.append(df_month)\n",
    "        print('The number of rows so far by adding ', month_file, \":\", df_months_combined.shape[0])\n",
    "\n",
    "df_months_combined['date_dataset'] = date_month\n",
    "\n",
    "# Aggregating data to year\n",
    "df_months_combined = df_months_combined.groupby(['date_dataset', \n",
    "                                                  'id_company', \n",
    "                                                  'id_branch']).agg({'has_relocated': 'max', \n",
    "                                                                     'date_month': 'max'})\n",
    "df_months_combined = df_months_combined.rename(index=str, columns={\"date_month\": \"date_month_last\"})\n",
    "df_months_combined = df_months_combined.reset_index()\n",
    "df_months_combined['date_dataset'] = pd.to_datetime(df_months_combined['date_dataset'])\n",
    "df_months_combined['id_company'] = df_months_combined['id_company'].astype(int)\n",
    "df_months_combined['id_branch'] = df_months_combined['id_branch'].astype(int)\n",
    "\n",
    "return(df_months_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
