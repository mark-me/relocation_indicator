{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLICOLOR': '1',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'HOME': '/home/mark_zwart76',\n",
       " 'JPY_PARENT_PID': '2079',\n",
       " 'LANG': 'en_US.UTF-8',\n",
       " 'LESSCLOSE': '/usr/bin/lesspipe %s %s',\n",
       " 'LESSOPEN': '| /usr/bin/lesspipe %s',\n",
       " 'LOGNAME': 'mark_zwart76',\n",
       " 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:',\n",
       " 'MAIL': '/var/mail/mark_zwart76',\n",
       " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       " 'PAGER': 'cat',\n",
       " 'PATH': '/home/mark_zwart76/bin:/home/mark_zwart76/.local/bin:/home/mark_zwart76/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin',\n",
       " 'PWD': '/home/mark_zwart76',\n",
       " 'SHELL': '/bin/bash',\n",
       " 'SHLVL': '1',\n",
       " 'SSH_AUTH_SOCK': '/tmp/ssh-2euci5jL9S/agent.2050',\n",
       " 'SSH_CLIENT': '74.125.73.33 61770 22',\n",
       " 'SSH_CONNECTION': '74.125.73.33 61770 10.142.0.3 22',\n",
       " 'SSH_TTY': '/dev/pts/0',\n",
       " 'TERM': 'xterm-color',\n",
       " 'USER': 'mark_zwart76',\n",
       " 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop',\n",
       " 'XDG_RUNTIME_DIR': '/run/user/1004',\n",
       " 'XDG_SESSION_ID': '1',\n",
       " '_': '/home/mark_zwart76/anaconda3/bin/jupyter-notebook'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cleaning_merging import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_dataset = datetime.strptime(\"2018-01-01\", '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = [\"2018-01-01\", \"2017-01-01\", \"2016-01-01\", \"2015-01-01\", \"2014-01-01\", \"2013-01-01\"]\n",
    "list_date_dataset = [datetime.strptime(date, '%Y-%m-%d') for date in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'\n",
    "dir_input_data = '01_input'\n",
    "dir_output_data = '02_cleaned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate clean and merge object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_merge = Cleaner_Merger(project, bucket_name, dir_input_data, dir_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = clean_merge.get_df_from_bucket(dir_input_data + \"/additional_data/location_start_date.CSV\",\n",
    "                           sep=',', na_values=['', '1198-06-12', 'NA'],\n",
    "                           parse_dates=['date_relocation_last', 'date_relocation_penultimate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features = clean_merge.get_features(date_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of company, branch, month combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_target = clean_merge.get_targets(date_dataset, columns_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of companies with target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_monthly = df_features.merge(df_target,\n",
    "                               on=['id_company', 'id_branch'],\n",
    "                               how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of monthly company branch data records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_monthly.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_monthly['has_relocated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_month = date_dataset\n",
    "\n",
    "df_months_combined = pd.DataFrame()  # The data frame which will contain all independent variables\n",
    "    \n",
    "# Get all months in range\n",
    "df_date_months = pd.DataFrame(pd.date_range(date_month, periods=12, freq=\"M\").tolist(),\n",
    "                              columns=['date_month'])\n",
    "df_date_months['date_month'] = df_date_months['date_month'].values.astype('datetime64[M]') # First day of month\n",
    "\n",
    "# Get the file names of all required month files\n",
    "#month_files = get_month_filenames(df_date_months, bucket, dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_files = [] # List of month files\n",
    "\n",
    "df_date_months['year'] = df_date_months.date_month.dt.year\n",
    "list_years = df_date_months['year'].unique()\n",
    "# If there are multiple years, iterate through years  \n",
    "for year in list_years:\n",
    "    # Get the year's data file names\n",
    "    dir_data_year = dir_data + '/' + str(year)\n",
    "    list_blob = list(bucket.list_blobs(prefix=dir_data_year))\n",
    "    # finding out which month files should be processed by looking which contain the first month date (YYYY-mm-01)\n",
    "    df_year_months = df_date_months[df_date_months['year'] == year]['date_month']\n",
    "    for blob in list_blob:\n",
    "        for month in df_year_months:\n",
    "            if (month.strftime(\"%Y-%m-%d\") in blob.name) & ('CSV' in blob.name):\n",
    "                month_files.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleaning, transforming and combining month files                \n",
    "for month_file in month_files:\n",
    "    with fs.open('graydon-data/' + month_file) as f:\n",
    "        df_month = pd.read_csv(f, sep=';', usecols= columns_features, index_col=False)   \n",
    "        df_month = df_month[(df_month['is_sole_proprietor'] == 0)] # & (one_month_df['is_discontinued'] == 0) \n",
    "        df_month.columns = (df_month.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', ''))\n",
    "        df_months_combined = df_months_combined.append(df_month)\n",
    "        print('The number of rows so far by adding ', month_file, \":\", df_months_combined.shape[0])\n",
    "\n",
    "df_months_combined['date_dataset'] = date_month\n",
    "\n",
    "# Aggregating data to year\n",
    "df_months_combined = df_months_combined.groupby(['date_dataset', \n",
    "                                                  'id_company', \n",
    "                                                  'id_branch']).agg({'has_relocated': 'max', \n",
    "                                                                     'date_month': 'max'})\n",
    "df_months_combined = df_months_combined.rename(index=str, columns={\"date_month\": \"date_month_last\"})\n",
    "df_months_combined = df_months_combined.reset_index()\n",
    "df_months_combined['date_dataset'] = pd.to_datetime(df_months_combined['date_dataset'])\n",
    "df_months_combined['id_company'] = df_months_combined['id_company'].astype(int)\n",
    "df_months_combined['id_branch'] = df_months_combined['id_branch'].astype(int)\n",
    "\n",
    "return(df_months_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
