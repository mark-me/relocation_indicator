{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading functions\n",
    "%run ../modules/common\n",
    "%run ../modules/cleaning_merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore 'dask' warning\n",
    "from datetime import datetime\n",
    "#from pandas import DataFrame\n",
    "from IPython.display import HTML\n",
    "from google.cloud.storage import Blob\n",
    "import datalab.storage as gcs_datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_dataset = datetime.strptime(\"2018-01-01\", '%Y-%m-%d')\n",
    "columns_targets = ['date_month', 'id_company', 'id_branch', 'is_sole_proprietor', 'has_relocated']\n",
    "columns_features = ['date_month', 'id_company', 'id_branch',\n",
    "                    'is_discontinued', 'financial_calamity_outcome', 'date_established', 'qty_employees', \n",
    "                    'year_qty_employees', 'id_company_creditproxy', 'score_payment_assessment', \n",
    "                    'amt_revenue', 'year_revenue', 'amt_consolidated_revenue', 'year_consolidated_revenue',\n",
    "                    'amt_consolidated_operating_result', 'year_consolidated_operating_result', \n",
    "                    'perc_credit_limit_adjustment', 'color_credit_status', 'rat_pd', 'score_pd',\n",
    "                    'has_increased_risk', 'is_sole_proprietor', 'code_SBI_2', 'code_SBI_1',\n",
    "                    'qty_address_mutations_total', 'qty_address_mutations_month', 'has_name_change', \n",
    "                    'code_discontinuation', 'code_financial_calamity', 'qty_issued_credit_reports', \n",
    "                    'Associate', 'Authorized official', 'Board member', 'Chairman', 'Commissioner', \n",
    "                    'Director', 'Liquidator', 'Major', 'Managing clerk', 'Managing partner', \n",
    "                    'Member of the partnership', 'Miscellaneous', 'Owner', 'Secretary', 'Secretary/Treasurer', \n",
    "                    'Treasurer', 'Unknown', 'Vice President', 'amt_operating_result', 'code_legal_form', \n",
    "                    'date_financial_calamity_started', 'date_financial_calamity_stopped', 'date_start', \n",
    "                    'from_date_start', 'qty_stopped_names', 'qty_started_names', 'year_operating_result']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up constants. All required\n",
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'\n",
    "dir_data = '01_input'\n",
    "gc_bucket = GCS_Bucket(name_project = project, name_bucket = bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bucket = gc_bucket.get_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Bucket' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5025f6199a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/graydon_moving_indicator/Notebooks/modules/cleaning_merging.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(date_month, columns_features, bucket, dir_data)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Get the file names of all required month files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mmonth_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_month_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_date_months\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Cleaning, transforming and combining month files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graydon_moving_indicator/Notebooks/modules/cleaning_merging.py\u001b[0m in \u001b[0;36mget_month_filenames\u001b[0;34m(df_date_months, bucket, dir_data)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_years\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Get the year's data file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mdir_data_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mlist_blob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_data_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# finding out which month files should be processed by looking which contain the first month date (YYYY-mm-01)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Bucket' and 'str'"
     ]
    }
   ],
   "source": [
    "df_features = get_features(date_dataset, columns_features, dir_data, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_month = date_dataset\n",
    "\n",
    "df_months_combined = pd.DataFrame()  # The data frame which will contain all independent variables\n",
    "    \n",
    "# Get all months in range\n",
    "df_date_months = pd.DataFrame(pd.date_range(date_month, periods=12, freq=\"M\").tolist(),\n",
    "                              columns=['date_month'])\n",
    "df_date_months['date_month'] = df_date_months['date_month'].values.astype('datetime64[M]') # First day of month\n",
    "\n",
    "# Get the file names of all required month files\n",
    "#month_files = get_month_filenames(df_date_months, bucket, dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_files = [] # List of month files\n",
    "\n",
    "df_date_months['year'] = df_date_months.date_month.dt.year\n",
    "list_years = df_date_months['year'].unique()\n",
    "# If there are multiple years, iterate through years  \n",
    "for year in list_years:\n",
    "    # Get the year's data file names\n",
    "    dir_data_year = dir_data + '/' + str(year)\n",
    "    list_blob = list(bucket.list_blobs(prefix=dir_data_year))\n",
    "    # finding out which month files should be processed by looking which contain the first month date (YYYY-mm-01)\n",
    "    df_year_months = df_date_months[df_date_months['year'] == year]['date_month']\n",
    "    for blob in list_blob:\n",
    "        for month in df_year_months:\n",
    "            if (month.strftime(\"%Y-%m-%d\") in blob.name) & ('CSV' in blob.name):\n",
    "                month_files.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_input/2018/modelling_2018-01-01_2018-01-31.CSV',\n",
       " '01_input/2018/modelling_2018-02-01_2018-02-28.CSV',\n",
       " '01_input/2018/modelling_2018-03-01_2018-03-31.CSV',\n",
       " '01_input/2018/modelling_2018-04-01_2018-04-30.CSV',\n",
       " '01_input/2018/modelling_2018-05-01_2018-05-31.CSV',\n",
       " '01_input/2018/modelling_2018-06-01_2018-06-30.CSV',\n",
       " '01_input/2018/modelling_2018-07-01_2018-07-31.CSV',\n",
       " '01_input/2018/modelling_2018-08-01_2018-08-31.CSV',\n",
       " '01_input/2018/modelling_2018-09-01_2018-09-30.CSV',\n",
       " '01_input/2018/modelling_2018-10-01_2018-10-31.CSV']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning, transforming and combining month files                \n",
    "for month_file in month_files:\n",
    "    with fs.open('graydon-data/' + month_file) as f:\n",
    "        df_month = pd.read_csv(f, sep=';', usecols= columns_features, index_col=False)   \n",
    "        df_month = df_month[(df_month['is_sole_proprietor'] == 0)] # & (one_month_df['is_discontinued'] == 0) \n",
    "        df_month.columns = (df_month.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', ''))\n",
    "        df_months_combined = df_months_combined.append(df_month)\n",
    "        print('The number of rows so far by adding ', month_file, \":\", df_months_combined.shape[0])\n",
    "\n",
    "df_months_combined['date_dataset'] = date_month\n",
    "\n",
    "# Aggregating data to year\n",
    "df_months_combined = df_months_combined.groupby(['date_dataset', \n",
    "                                                  'id_company', \n",
    "                                                  'id_branch']).agg({'has_relocated': 'max', \n",
    "                                                                     'date_month': 'max'})\n",
    "df_months_combined = df_months_combined.rename(index=str, columns={\"date_month\": \"date_month_last\"})\n",
    "df_months_combined = df_months_combined.reset_index()\n",
    "df_months_combined['date_dataset'] = pd.to_datetime(df_months_combined['date_dataset'])\n",
    "df_months_combined['id_company'] = df_months_combined['id_company'].astype(int)\n",
    "df_months_combined['id_branch'] = df_months_combined['id_branch'].astype(int)\n",
    "\n",
    "return(df_months_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
