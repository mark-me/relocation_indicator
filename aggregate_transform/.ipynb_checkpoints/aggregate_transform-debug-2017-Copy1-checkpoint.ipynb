{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ignore 'dask' warning\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "from pandas import DataFrame\n",
    "from IPython.display import HTML\n",
    "from google.cloud.storage import Blob\n",
    "import datalab.storage as gcs_datalab\n",
    "from datetime import date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up constants. All required\n",
    "project = 'graydon-moving-indicator'\n",
    "bucket_name = 'graydon-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing bucket\n",
    "fs = gcsfs.GCSFileSystem(project='graydon-moving-indicator')\n",
    "gcs = storage.Client()\n",
    "bucket = gcs.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-aggregation\n",
    "def create_dict_types_original_data():\n",
    "    # Setting up dictionary of column types\n",
    "    dtype={ 'id_company'  :np.float64,\n",
    "        'id_branch'    :np.int64,\n",
    "        'is_discontinued':bool,\n",
    "        'code_discontinuation': np.float64,\n",
    "        'code_financial_calamity':object,\n",
    "        'financial_calamity_outcome'   : np.float64,\n",
    "        'code_legal_form' : np.float64,\n",
    "        'qty_employees' :np.float64,\n",
    "        'year_qty_employees' :np.float64,\n",
    "        'id_company_creditproxy':object,\n",
    "        'score_payment_assessment'    : np.float64,\n",
    "        'amt_revenue'  : np.float64,\n",
    "        'year_revenue'  : np.float64,\n",
    "        'amt_operating_result'   : np.float64,\n",
    "        'year_operating_result'    :object,\n",
    "        'amt_consolidated_revenue'   : np.float64,\n",
    "        'year_consolidated_revenue'   :object,\n",
    "        'amt_consolidated_operating_result'     : np.float64,\n",
    "        'year_consolidated_operating_result'   :object,\n",
    "        'qty_issued_credit_reports' : np.float64,\n",
    "        'perc_credit_limit_adjustment' :object,\n",
    "        'color_credit_status'  :object,\n",
    "        'rat_pd'              :object,\n",
    "        'score_pd'            : np.float64,\n",
    "        'has_increased_risk'  :bool,\n",
    "        'is_sole_proprietor'   :bool,\n",
    "        'code_sbi_2'         : np.float64,\n",
    "        'qty_address_mutations_total'  :np.float64,\n",
    "        'qty_address_mutations_month'   :np.float64,\n",
    "        'has_relocated':bool,\n",
    "        'qty_started_names': np.float64,\n",
    "        'qty_stopped_names': np.float64,\n",
    "        'total_changeof_board_members_' :np.float64\n",
    "    }\n",
    "    return dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_parse_dates_list_original_data():\n",
    "    # Setting up dictionary of column types\n",
    "    parse_dates = ['date_established' , 'date_financial_calamity_started',\n",
    "        'date_financial_calamity_stopped', 'date_month', 'date_relocation_last']\n",
    "    return parse_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_one_year_from_bucket_merged_csv(year, dir_prefix = ''):\n",
    "    \"\"\" Reads a whole year of data from the already merged files \"\"\"\n",
    "    dtype = create_dict_types_original_data()\n",
    "    parse_dates = create_parse_dates_list_original_data()\n",
    "    full_year_df = pd.DataFrame()\n",
    "    print('Starting with year: ', year)\n",
    "    print(dir_prefix)\n",
    "    blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "    for blob in blob_list:  \n",
    "        print(\"blob\", blob.name)\n",
    "        if year in blob.name:\n",
    "            print('Processing file: ', blob.name)\n",
    "            with fs.open('graydon-data/' + blob.name) as f:\n",
    "                full_year_df = pd.read_csv(f, sep=',', index_col=0, dtype=dtype, parse_dates=parse_dates \n",
    "                                        )   \n",
    "        print('The number of rows so far is: ', full_year_df.shape[0])\n",
    "    return full_year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ages of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_age_based_on_date(df, col_list):\n",
    "    df['max_date_month'] = df.groupby(['id_branch', 'id_company']).date_month.transform('max')\n",
    "    df['max_date_month_year'] = df['max_date_month'].apply(lambda x: x.year)\n",
    "    for col in col_list:\n",
    "        if col == 'date_established':\n",
    "            df['temp_date_established_year'] = df.date_established.apply(lambda x: x.year)\n",
    "            df['company_age'] = df['max_date_month_year'] - df.temp_date_established_year \n",
    "            df = df.drop(labels =['temp_date_established_year'], axis= 1)\n",
    "        elif col == 'date_relocation_last':\n",
    "            #print(df.columns)\n",
    "            df['max_date_relocation_last'] = df.groupby(['id_branch', 'id_company']).date_relocation_last.transform('max')\n",
    "            df['temp_max_date_relocation_last_year'] = df.max_date_relocation_last.apply(lambda x: x.year)\n",
    "            df['years_in_current_location'] = df['max_date_month_year'] - df.temp_max_date_relocation_last_year \n",
    "            df = df.drop(labels =['temp_max_date_relocation_last_year', 'max_date_relocation_last' ], axis= 1)\n",
    "        elif col == 'year_consolidated_operating_result':            \n",
    "            mask = (df['year_consolidated_operating_result'].astype(float) > 0)\n",
    "            df_valid = df[mask]\n",
    "            df['years_since_last_amt_consolidated_operating_result'] = np.nan\n",
    "            df.loc[mask, 'years_since_last_amt_consolidated_operating_result'] = (df['max_date_month_year'] - \n",
    "                                df_valid.year_consolidated_operating_result.astype(float))  \n",
    "        elif col == 'year_consolidated_revenue':\n",
    "            mask = (df['year_consolidated_revenue'].astype(float) > 0)\n",
    "            df_valid = df[mask]\n",
    "            df['years_since_last_amt_consolidated_revenue'] = np.nan\n",
    "            df.loc[mask, 'years_since_last_amt_consolidated_revenue'] = (df['max_date_month_year'] - \n",
    "                                df_valid.year_consolidated_revenue.astype(float))    \n",
    "        elif col == 'year_operating_result':\n",
    "            mask = (df['year_operating_result'].astype(float) > 0)\n",
    "            df_valid = df[mask]\n",
    "            df['years_since_last_amt_operating_result'] = np.nan\n",
    "            df.loc[mask, 'years_since_last_amt_operating_result'] = (df['max_date_month_year'] - \n",
    "                                df_valid.year_operating_result.astype(float))    \n",
    "        elif col == 'year_qty_employees':\n",
    "            mask = (df['year_qty_employees'].astype(float) > 0)\n",
    "            df_valid = df[mask]\n",
    "            df['years_since_last_qty_employees'] = np.nan\n",
    "            df.loc[mask, 'years_since_last_qty_employees'] = (df['max_date_month_year'] - \n",
    "                                df_valid.year_qty_employees.astype(float))  \n",
    "        elif col == 'year_revenue':\n",
    "            mask = (df['year_revenue'].astype(float) > 0)\n",
    "            df_valid = df[mask]\n",
    "            df['years_since_last_amt_revenue'] = np.nan\n",
    "            df.loc[mask, 'years_since_last_amt_revenue'] = (df['max_date_month_year'] - \n",
    "                                df_valid.year_revenue.astype(float)) \n",
    "    df = df.drop(labels =['max_date_month', 'max_date_month_year'], axis= 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_of_column(df, col_list):\n",
    "    subset_columns = ['date_month', 'id_company', 'id_branch']\n",
    "    subset_columns.extend(col_list)\n",
    "    temp_df = df.reset_index().loc[:, subset_columns].sort_values(['id_company','id_branch', 'date_month'])\n",
    "    temp_df = temp_df.groupby(['id_branch', 'id_company']).agg(['first', 'last'])\n",
    "    for col in col_list:\n",
    "        if col == 'qty_employees':\n",
    "            temp_df['delta_qty_employees'] = temp_df['qty_employees']['last'] - temp_df['qty_employees']['first']    \n",
    "        elif col == 'qty_issued_credit_reports':\n",
    "            temp_df['delta_qty_issued_credit_reports'] = (temp_df['qty_issued_credit_reports']['last'] - \n",
    "                                                          temp_df['qty_issued_credit_reports']['first'] )\n",
    "        elif col == 'score_payment_assessment':\n",
    "            temp_df['delta_score_payment_assessment'] = (temp_df['score_payment_assessment']['last'] - \n",
    "                                                          temp_df['score_payment_assessment']['first'] )\n",
    "        elif col == 'score_pd':\n",
    "            temp_df['delta_score_pd'] = (temp_df['score_pd']['last'] - \n",
    "                                                          temp_df['score_pd']['first'] )\n",
    "        elif col == 'code_legal_form':\n",
    "            temp_df['code_legal_form_has_changed'] = (temp_df['code_legal_form']['last'] !=\n",
    "                                                          temp_df['code_legal_form']['first'] )\n",
    "        elif col == 'code_SBI_2_group':\n",
    "            temp_df['SBI_has_changed'] = (temp_df['code_SBI_2_group']['last'] !=\n",
    "                                                          temp_df['code_SBI_2_group']['first'] )   \n",
    "    temp_df.columns = temp_df.columns.droplevel(1)\n",
    "    temp_df = temp_df.loc[:,~temp_df.columns.duplicated()]\n",
    "    temp_df = temp_df.drop(axis=1, columns=col_list)        \n",
    "    df = df.merge(temp_df, how='left', on=['date_month', 'id_company', 'id_branch']) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If any true then true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_if_any_true(df, col_list):\n",
    "    for col in col_list:\n",
    "        if col == 'is_discontinued': \n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['is_discontinued'] \n",
    "                        .any()              # True if any items are True\n",
    "                        .rename('is_discontinued_any')    # name Series \n",
    "                        .to_frame()         # make a dataframe for merging\n",
    "                        .reset_index())\n",
    "        elif col == 'code_financial_calamity':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['code_financial_calamity'] \n",
    "                        .any()            \n",
    "                        .rename('has_financial_calamity')   \n",
    "                        .to_frame() \n",
    "                        .reset_index())\n",
    "        elif col == 'has_relocated':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['has_relocated'] \n",
    "                        .any()            \n",
    "                        .rename('has_relocated_next_year')   \n",
    "                        .to_frame() \n",
    "                        .reset_index())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_mean_of_column(df, col_list):\n",
    "    for col in col_list:\n",
    "        if col == 'amt_consolidated_operating_result':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['amt_consolidated_operating_result'] \n",
    "                        .agg('mean')             \n",
    "                        .rename('mean_amt_consolidated_operating_result')    \n",
    "                        .to_frame()       \n",
    "                        .reset_index())\n",
    "        if col == 'amt_consolidated_revenue':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['amt_consolidated_revenue'] \n",
    "                        .agg('mean')              \n",
    "                        .rename('mean_amt_consolidated_revenue')    \n",
    "                        .to_frame()      \n",
    "                        .reset_index())\n",
    "        if col == 'amt_operating_result':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['amt_operating_result'] \n",
    "                        .agg('mean')           \n",
    "                        .rename('mean_amt_operating_result')    \n",
    "                        .to_frame()         \n",
    "                        .reset_index())\n",
    "        if col == 'amt_revenue':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['amt_revenue']\n",
    "                        .agg('mean')        \n",
    "                        .rename('mean_amt_revenue')   \n",
    "                        .to_frame()     \n",
    "                        .reset_index())\n",
    "        if col == 'qty_employees':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['qty_employees'] \n",
    "                        .agg('mean')          \n",
    "                        .rename('mean_qty_employees')    \n",
    "                        .to_frame()       \n",
    "                        .reset_index())\n",
    "        if col == 'qty_issued_credit_reports':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['qty_issued_credit_reports'] \n",
    "                        .agg('mean')       \n",
    "                        .rename('mean_qty_issued_credit_reports')    \n",
    "                        .to_frame()        \n",
    "                        .reset_index())\n",
    "        if col == 'score_payment_assessment':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['score_payment_assessment'] \n",
    "                        .agg('mean')       \n",
    "                        .rename('mean_score_payment_assessment')    \n",
    "                        .to_frame()        \n",
    "                        .reset_index())\n",
    "        if col == 'score_pd':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['score_pd'] \n",
    "                        .agg('mean')       \n",
    "                        .rename('mean_score_pd')    \n",
    "                        .to_frame()        \n",
    "                        .reset_index())        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies into counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def column_dummies_into_counts(df, col_list):\n",
    "    df = df.reset_index()\n",
    "    subset_columns = ['id_branch']\n",
    "    subset_columns.extend(col_list)\n",
    "    df['unique_id'] =  df['id_branch'].astype(str) + '_' + df['id_company'].astype(str)\n",
    "    for col in col_list:\n",
    "        temp_df = df.loc[:, subset_columns]\n",
    "        if col == 'color_credit_status':\n",
    "            temp_df = pd.crosstab(df['unique_id'], df['color_credit_status']).reset_index().rename_axis(None,\n",
    "                                                                                                        axis=1).rename(\n",
    "                columns={\"G\": \"qty_green_flags\", \"O\": \"qty_orange_flags\",\"R\": \"qty_red_flags\"})\n",
    "        elif col == 'rat_pd':\n",
    "            temp_df = pd.crosstab(df['unique_id'], df['rat_pd']).reset_index().rename_axis(None, axis=1)\n",
    "        elif col == 'code_SBI_2_group':\n",
    "            temp_df = pd.crosstab(df['unique_id'], df['code_SBI_2_group']).reset_index().rename_axis(None,\n",
    "                                                                                                        axis=1).rename(\n",
    "                columns={\"1\": \"SBI_group_1\", \"2\": \"SBI_group_2\"})\n",
    "        elif col == 'code_legal_form_group':\n",
    "            temp_df = pd.crosstab(df['unique_id'], df['code_legal_form_group']).reset_index().rename_axis(None,\n",
    "                                                                                                        axis=1).rename(\n",
    "                columns={\"1\": \"code_legal_form_group_1\", \"2\": \"code_legal_form_group_2\"})\n",
    "        df = df.merge(temp_df, how='left', on= ['unique_id']) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_ratio_of_column(df, col_list):\n",
    "    for col in col_list:\n",
    "        subset_columns = ['id_branch']\n",
    "        subset_columns.extend(col)\n",
    "        temp_df = df.loc[:, subset_columns]\n",
    "        if col == 'amt_operating_result':\n",
    "            temp_df = df.groupby(['id_branch', 'id_company'])\n",
    "            temp_df = temp_df.agg({'amt_operating_result': 'sum', 'amt_consolidated_operating_result': 'sum'}).rename(\n",
    "    columns={'amt_operating_result': 'sum_amt_operating_result', \n",
    "             'amt_consolidated_operating_result': 'sum_amt_consolidated_operating_result'})\n",
    "            temp_df['ratio_operating_result_consolidated_operating_result'] = np.divide(\n",
    "                temp_df['sum_amt_operating_result'], temp_df['sum_amt_consolidated_operating_result'])\n",
    "            temp_df = temp_df.reset_index()\n",
    "            temp_df = temp_df.drop(axis=1, columns=['sum_amt_consolidated_operating_result', \n",
    "                                                    'sum_amt_operating_result'])\n",
    "            df = df.merge(temp_df, how='left', on= ['id_branch', 'id_company'])  \n",
    "        elif col == 'amt_revenue':\n",
    "            temp_df = df.groupby(['id_branch', 'id_company'])\n",
    "            temp_df = temp_df.agg({'amt_revenue': 'sum', 'amt_consolidated_revenue': 'sum'}).rename(\n",
    "    columns={'amt_revenue': 'sum_amt_revenue', \n",
    "             'amt_consolidated_revenue': 'sum_amt_consolidated_revenue'})\n",
    "            temp_df['ratio_revenue_consolidated_revenue'] = np.divide(temp_df['sum_amt_revenue'],\n",
    "                                                                     temp_df['sum_amt_consolidated_revenue'])\n",
    "            temp_df = temp_df.reset_index()\n",
    "            temp_df = temp_df.drop(axis=1, columns=['sum_amt_revenue', 'sum_amt_consolidated_revenue'])\n",
    "            df = df.merge(temp_df, how='left',  on= ['id_branch', 'id_company'])  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sum_of_column(df, col_list):\n",
    "    # List of 'based on'-'write to' column pairs to read-write values from-to\n",
    "    list_column_pairs = [['qty_address_mutations_month', 'qty_address_mutations_year'],\n",
    "                         ['qty_started_names', 'qty_started_names_year'],\n",
    "                         ['qty_stopped_names', 'qty_stopped_names_year'],\n",
    "                         ['total_changeof_board_members_', 'qty_board_changes_year']]\n",
    "    key_aggregattion = ['id_branch', 'id_company']\n",
    "    for column_pair in list_column_pairs:\n",
    "        df = df.merge(df.groupby(key_aggregattion)[column_pair[0]] \n",
    "                      .agg('sum')             \n",
    "                      .rename(column_pair[1])    \n",
    "                      .to_frame()       \n",
    "                      .reset_index())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_variance_of_column(df, col_list):\n",
    "    for col in col_list:\n",
    "        if col == 'qty_employees':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['qty_employees'] \n",
    "                        .agg('var')             \n",
    "                        .rename('variance_qty_employees')    \n",
    "                        .to_frame()       \n",
    "                        .reset_index())\n",
    "        elif col == 'qty_issued_credit_reports':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['qty_issued_credit_reports'] \n",
    "                        .agg('var')              \n",
    "                        .rename('variance_qty_issued_credit_reports')    \n",
    "                        .to_frame()      \n",
    "                        .reset_index())\n",
    "        elif col == 'score_payment_assessment':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['score_payment_assessment'] \n",
    "                        .agg('sum')           \n",
    "                        .rename('variance_score_payment_assessment')    \n",
    "                        .to_frame()         \n",
    "                        .reset_index())\n",
    "        elif col == 'score_pd':\n",
    "            df = df.merge(df.groupby(['id_branch', 'id_company'])['score_pd']\n",
    "                        .agg('sum')        \n",
    "                        .rename('variance_score_pd')   \n",
    "                        .to_frame()     \n",
    "                        .reset_index())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get has_relocated from next year DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_has_relocated_with_nextyear(df, next_year, dir_prefix = ''):\n",
    "    dtype={ \n",
    "            'id_branch'    :np.int64,\n",
    "            'id_company'    :np.int64,\n",
    "            'has_relocated':bool\n",
    "    }\n",
    "    full_next_year_df = pd.DataFrame()\n",
    "    cols = ['id_company', 'id_branch', 'has_relocated']\n",
    "    print('Starting withGra year: ', next_year)\n",
    "    print(dir_prefix)\n",
    "    blob_list = list(bucket.list_blobs(prefix=dir_prefix))    \n",
    "    for blob in blob_list:         \n",
    "        if str(next_year) in blob.name:\n",
    "            print('Processing file: ', blob.name)\n",
    "            with fs.open('graydon-data/' + blob.name) as f:\n",
    "                full_next_year_df = pd.read_csv(f, sep=',',  dtype=dtype, usecols= cols\n",
    "                                     )   \n",
    "        print('The number of rows so far is: ', full_next_year_df.shape[0])\n",
    "    full_next_year_df = calculate_if_any_true(full_next_year_df, col_list = ['has_relocated'])\n",
    "    full_next_year_df = full_next_year_df.drop(axis=1, columns='has_relocated')\n",
    "    full_next_year_df = full_next_year_df.drop_duplicates().reset_index().drop(axis=1, columns='index')\n",
    "    df = df.merge(full_next_year_df, on=['id_branch', 'id_company'], how='left', suffixes='_C')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating SBI code groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sbi_groups(df):\n",
    "    code_SBI_2_group1 = [1,19,35,51,53,59,61,62,63,69,72,73,74,78,79,80,82,85,86,87,88,90,93,94]\n",
    "    df['code_SBI_2_group'] = np.where(df['code_sbi_2'].isin(code_SBI_2_group1), \"1\", \"2\")\n",
    "    df = df.drop(axis=1, labels='code_sbi_2', inplace=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating code legal from groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_code_legal_form_groups(df):\n",
    "    code_legal_form_group = [1,4,6,7,8,9,15,17,18]\n",
    "    df['code_legal_form_group'] = np.where(df['code_legal_form'].isin(code_legal_form_group), \"1\", \"2\")\n",
    "    df = df.drop(axis=1, labels='code_legal_form', inplace=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping old columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_old_columns(df, col_list):\n",
    "    df = df.drop(axis=1, labels=col_list, inplace=False)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deduplicating rows of original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deduplicate_rows(df):\n",
    "    df = df.groupby(['id_branch', 'id_company']).first()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(axis=1, columns='index')\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning after aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_after_aggregations(df):\n",
    "    df[['has_financial_calamity', 'is_discontinued_any', 'SBI_has_changed'\n",
    "        ,'code_legal_form_has_changed']] = df[['has_financial_calamity', 'is_discontinued_any',\n",
    "                                                'code_legal_form_has_changed', 'SBI_has_changed']].fillna(value=False)\n",
    "    \n",
    "    columns_to_zero = ['mean_qty_issued_credit_reports', 'qty_green_flags', 'qty_orange_flags', \n",
    "                       'qty_red_flags', 'AAA', 'AA', 'A', 'BBB', 'B' , 'CCC', 'CC', 'C', 'D', \n",
    "                       'NR', 'qty_address_mutations_year', 'qty_started_names_year', \n",
    "                       'qty_stopped_names_year', 'qty_board_changes_year', 'code_legal_form_group_1', \n",
    "                       'code_legal_form_group_2', 'SBI_group_1', 'SBI_group_2']\n",
    "    \n",
    "    df[columns_to_zero] = df[columns_to_zero].fillna(value=0)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving DF locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df_locally(df, dir_prefix, year, as_json= False):\n",
    "    \"\"\" Saves df as json or csv locally on server \"\"\"\n",
    "    if as_json:        \n",
    "        file_path = dir_prefix + '/' + year + '_aggregated.json'\n",
    "        df.to_json(file_path)\n",
    "    else:\n",
    "        file_path =  dir_prefix + '/' + year + '_aggregated.csv'\n",
    "        df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating dataframe into one year. Main function that calls them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregating dataframe into one year. Main function that calls them all\n",
    "def aggregate_full_year(year, dir_prefix = '', save_df_locally_flag = False):\n",
    "    \n",
    "    next_year = int(year) + 1\n",
    "    \n",
    "    print('Reading DF for year ', year) \n",
    "    df = read_one_year_from_bucket_merged_csv(year, dir_prefix)\n",
    "    \n",
    "    print('Creating SBI groups ')\n",
    "    df = create_sbi_groups(df)\n",
    "    print('Done creating SBI groups')\n",
    "    \n",
    "    print('Calculating delta of variables ')\n",
    "    df = calculate_delta_of_column(df, col_list=['qty_employees','qty_issued_credit_reports', \n",
    "                                                        'score_payment_assessment',\n",
    "                                                       'code_legal_form', 'code_SBI_2_group'])\n",
    "    print('Done calculating delta of variables ') \n",
    "    \n",
    "    print('Creating code legal form groups ')\n",
    "    df = create_code_legal_form_groups(df)\n",
    "    print('Done creating code legal form groups')\n",
    "    \n",
    "    print('Calculating ages of variables ')\n",
    "    df = calculate_age_based_on_date(df,['date_established', 'year_consolidated_operating_result', \n",
    "                                         'year_consolidated_revenue',\n",
    "                                        'year_operating_result', 'year_qty_employees', 'year_revenue', 'date_relocation_last'])\n",
    "    print('Done calculating ages of variables ')\n",
    "    \n",
    "    print('Calculating ratio of columns')\n",
    "    df = calculate_ratio_of_column(df, col_list=['amt_operating_result',\n",
    "                                                        'amt_consolidated_operating_result',\n",
    "                                                         'amt_revenue',\n",
    "                                                        'amt_consolidated_revenue'])\n",
    "    print('Done calculating ratio of columns')\n",
    "        \n",
    "    print('Making dummies into counts')\n",
    "    df = column_dummies_into_counts(df, col_list=['color_credit_status','rat_pd', 'code_legal_form_group',\n",
    "                                                  'code_SBI_2_group'])\n",
    "    print('Done making dummies into counts')\n",
    "    \n",
    " \n",
    "    print('Calculating if any true ')\n",
    "    df = calculate_if_any_true(df, col_list=['is_discontinued', 'code_financial_calamity'])\n",
    "    print('Done calculating if any true ')\n",
    "    \n",
    "    print('Calculating mean of columns ')\n",
    "    df = calculate_mean_of_column(df, col_list=['amt_consolidated_operating_result', \n",
    "                                                        'amt_consolidated_revenue',\n",
    "                                                       'amt_operating_result','amt_revenue',\n",
    "                                                       'qty_employees', 'qty_issued_credit_reports',\n",
    "                                                      'score_payment_assessment' , \n",
    "                                                       'score_pd'])\n",
    "    print('Done calculating mean of columns ')\n",
    "    \n",
    "    print('Calculating sum of columns')\n",
    "    df = calculate_sum_of_column(df, col_list=['qty_address_mutations_month',\n",
    "                                                        'qty_started_names',\n",
    "                                                         'qty_stopped_names',\n",
    "                                                        'total_changeof_board_members_']) \n",
    "    print('Done calculating sum of columns')\n",
    "    \n",
    "    print('Calculating variance of columns')\n",
    "    df = calculate_variance_of_column(df, col_list=['qty_employees',\n",
    "                                                        'qty_issued_credit_reports',\n",
    "                                                         'score_payment_assessment',\n",
    "                                                        'score_pd']) \n",
    "    print('Done calculating variance of columns')\n",
    "\n",
    "\n",
    " \n",
    "    print('Dropping old columns')\n",
    "    df = drop_old_columns(df, col_list = ['date_established', 'year_consolidated_operating_result', \n",
    "                                          'year_consolidated_revenue', \n",
    "                                          'year_operating_result', 'year_qty_employees', 'year_revenue',\n",
    "                                          'is_discontinued', 'code_financial_calamity', \n",
    "                                          'amt_consolidated_operating_result', 'amt_consolidated_revenue', \n",
    "                                          'amt_operating_result','amt_revenue','qty_employees', \n",
    "                                          'qty_issued_credit_reports', 'score_payment_assessment' ,\n",
    "                                          'score_pd', 'color_credit_status','rat_pd',\n",
    "                                          'qty_address_mutations_month','qty_started_names',\n",
    "                                          'qty_stopped_names', 'total_changeof_board_members_', 'is_sole_proprietor',\n",
    "                                          'code_discontinuation','date_financial_calamity_started', \n",
    "                                          'date_financial_calamity_stopped', 'id_company_creditproxy', \n",
    "                                          'financial_calamity_outcome', 'has_increased_risk' , \n",
    "                                          'perc_credit_limit_adjustment',\n",
    "                                          'date_start', 'from_date_start', 'qty_address_mutations_total',\n",
    "                                          'code_legal_form_group', 'code_SBI_2_group', 'date_relocation_last', \n",
    "                                          'date_relocation_penultimate'])\n",
    "    print('Done dropping old columns')\n",
    "\n",
    "    print(' Deduplicating rows of original dataframe')\n",
    "    df = deduplicate_rows(df)\n",
    "    print(' Done deduplicating rows of original dataframe')\n",
    "   \n",
    "    print('Getting target of next year and adding it as a column') \n",
    "    df = replace_has_relocated_with_nextyear(df= df, next_year= next_year,\n",
    "                                   dir_prefix= 'including_scores/merged_per_year/merged_cleaned/relocation_dates')\n",
    "    print('Done getting target of next year and adding it as a column' )\n",
    "    \n",
    "    print(' Cleaning aggregated data frame ')\n",
    "    df = clean_after_aggregations(df)\n",
    "    print('Done cleaning and aggreating dataframe')\n",
    "    \n",
    "    if save_df_locally_flag:\n",
    "        print('Saving DF local to VM into files_to_bucket folder')\n",
    "        save_df_locally(df= df, dir_prefix= 'files_to_bucket/aggregated', year = year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DF for year  2017\n",
      "Starting with year:  2017\n",
      "02_clean\n",
      "blob 02_cleaned/2013_merged.csv\n",
      "The number of rows so far is:  0\n",
      "blob 02_cleaned/2014_merged.csv\n",
      "The number of rows so far is:  0\n",
      "blob 02_cleaned/2015_merged.csv\n",
      "The number of rows so far is:  0\n",
      "blob 02_cleaned/2016_merged.csv\n",
      "The number of rows so far is:  0\n",
      "blob 02_cleaned/2017_merged.csv\n",
      "Processing file:  02_cleaned/2017_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (32,35,36,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows so far is:  22729762\n"
     ]
    }
   ],
   "source": [
    "year = '2017'\n",
    "dir_prefix = '02_clean'\n",
    "\n",
    "next_year = int(year) + 1\n",
    "print('Reading DF for year ', year) \n",
    "df = read_one_year_from_bucket_merged_csv(year, dir_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22729762"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in true_divide\n",
      "  \n",
      "/home/mrodriguezlara/graydon/graydon-moving/lib/python3.5/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "col = ['amt_operating_result', 'amt_consolidated_operating_result', 'ratio_operating_result_consolidated_operating_result']\n",
    "key_aggregattion = ['id_branch', 'id_company']\n",
    "subset_columns =  key_aggregattion + [col[0], col[1]]\n",
    "\n",
    "temp_df = df.loc[:, subset_columns]\n",
    "temp_df = df.groupby(key_aggregattion)\n",
    "temp_df = temp_df.agg({col[0]: 'sum', col[1]: 'sum'})\n",
    "temp_df[col[2]] = np.divide(temp_df[col[0]], temp_df[col[1]],  where=col[1]!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>amt_operating_result</th>\n",
       "      <th>amt_consolidated_operating_result</th>\n",
       "      <th>ratio_operating_result_consolidated_operating_result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_branch</th>\n",
       "      <th>id_company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">0</th>\n",
       "      <th>428134.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803351.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810695.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811258.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811333.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818258.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823722.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829630.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834432.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834909.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847212.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853730.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854070.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860012.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867886.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868180.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876537.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885130.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895625.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898359.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899008.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904865.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912895.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913198.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913550.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920639.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921671.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922102.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928972.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928976.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618833</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618841</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618868</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618876</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618884</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618892</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618906</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618914</th>\n",
       "      <th>912221658.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618922</th>\n",
       "      <th>897344855.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.364387e-316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618930</th>\n",
       "      <th>914816462.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618949</th>\n",
       "      <th>899778.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618957</th>\n",
       "      <th>899778.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618965</th>\n",
       "      <th>899778.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618973</th>\n",
       "      <th>899778.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72618981</th>\n",
       "      <th>890167052.0</th>\n",
       "      <td>9.227696e-317</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619007</th>\n",
       "      <th>1312330.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619015</th>\n",
       "      <th>1085817.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619023</th>\n",
       "      <th>1001695.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619031</th>\n",
       "      <th>922458693.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619058</th>\n",
       "      <th>923759476.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619066</th>\n",
       "      <th>931021812.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72619074</th>\n",
       "      <th>931021812.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72624752</th>\n",
       "      <th>902929364.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72624760</th>\n",
       "      <th>899336736.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72624779</th>\n",
       "      <th>872971.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72626895</th>\n",
       "      <th>904267083.0</th>\n",
       "      <td>2.550493e-314</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72626909</th>\n",
       "      <th>929134788.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72627301</th>\n",
       "      <th>245384.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72627328</th>\n",
       "      <th>893632120.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72627352</th>\n",
       "      <th>929534093.0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1966208 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       amt_operating_result  \\\n",
       "id_branch id_company                          \n",
       "0         428134.0             0.000000e+00   \n",
       "          803351.0             0.000000e+00   \n",
       "          810695.0             0.000000e+00   \n",
       "          811258.0             0.000000e+00   \n",
       "          811333.0             0.000000e+00   \n",
       "          818258.0             0.000000e+00   \n",
       "          823722.0             0.000000e+00   \n",
       "          829630.0             0.000000e+00   \n",
       "          834432.0             0.000000e+00   \n",
       "          834909.0             0.000000e+00   \n",
       "          847212.0             0.000000e+00   \n",
       "          853730.0             0.000000e+00   \n",
       "          854070.0             0.000000e+00   \n",
       "          860012.0             0.000000e+00   \n",
       "          867886.0             0.000000e+00   \n",
       "          868180.0             0.000000e+00   \n",
       "          876537.0             0.000000e+00   \n",
       "          885130.0             0.000000e+00   \n",
       "          895625.0             0.000000e+00   \n",
       "          898359.0             0.000000e+00   \n",
       "          899008.0             0.000000e+00   \n",
       "          904865.0             0.000000e+00   \n",
       "          912895.0             0.000000e+00   \n",
       "          913198.0             0.000000e+00   \n",
       "          913550.0             0.000000e+00   \n",
       "          920639.0             0.000000e+00   \n",
       "          921671.0             0.000000e+00   \n",
       "          922102.0             0.000000e+00   \n",
       "          928972.0             0.000000e+00   \n",
       "          928976.0             0.000000e+00   \n",
       "...                                     ...   \n",
       "72618833  912221658.0          0.000000e+00   \n",
       "72618841  912221658.0          0.000000e+00   \n",
       "72618868  912221658.0          0.000000e+00   \n",
       "72618876  912221658.0          0.000000e+00   \n",
       "72618884  912221658.0          0.000000e+00   \n",
       "72618892  912221658.0          0.000000e+00   \n",
       "72618906  912221658.0          0.000000e+00   \n",
       "72618914  912221658.0          0.000000e+00   \n",
       "72618922  897344855.0          0.000000e+00   \n",
       "72618930  914816462.0          0.000000e+00   \n",
       "72618949  899778.0             0.000000e+00   \n",
       "72618957  899778.0             0.000000e+00   \n",
       "72618965  899778.0             0.000000e+00   \n",
       "72618973  899778.0             0.000000e+00   \n",
       "72618981  890167052.0         9.227696e-317   \n",
       "72619007  1312330.0            0.000000e+00   \n",
       "72619015  1085817.0            0.000000e+00   \n",
       "72619023  1001695.0            0.000000e+00   \n",
       "72619031  922458693.0          0.000000e+00   \n",
       "72619058  923759476.0          0.000000e+00   \n",
       "72619066  931021812.0          0.000000e+00   \n",
       "72619074  931021812.0          0.000000e+00   \n",
       "72624752  902929364.0          0.000000e+00   \n",
       "72624760  899336736.0          0.000000e+00   \n",
       "72624779  872971.0             0.000000e+00   \n",
       "72626895  904267083.0         2.550493e-314   \n",
       "72626909  929134788.0          0.000000e+00   \n",
       "72627301  245384.0             0.000000e+00   \n",
       "72627328  893632120.0          0.000000e+00   \n",
       "72627352  929534093.0          0.000000e+00   \n",
       "\n",
       "                       amt_consolidated_operating_result  \\\n",
       "id_branch id_company                                       \n",
       "0         428134.0                          0.000000e+00   \n",
       "          803351.0                          0.000000e+00   \n",
       "          810695.0                          0.000000e+00   \n",
       "          811258.0                          0.000000e+00   \n",
       "          811333.0                          0.000000e+00   \n",
       "          818258.0                          0.000000e+00   \n",
       "          823722.0                          0.000000e+00   \n",
       "          829630.0                          0.000000e+00   \n",
       "          834432.0                          0.000000e+00   \n",
       "          834909.0                          0.000000e+00   \n",
       "          847212.0                          0.000000e+00   \n",
       "          853730.0                          0.000000e+00   \n",
       "          854070.0                          0.000000e+00   \n",
       "          860012.0                          0.000000e+00   \n",
       "          867886.0                          0.000000e+00   \n",
       "          868180.0                          0.000000e+00   \n",
       "          876537.0                          0.000000e+00   \n",
       "          885130.0                          0.000000e+00   \n",
       "          895625.0                          0.000000e+00   \n",
       "          898359.0                          0.000000e+00   \n",
       "          899008.0                          0.000000e+00   \n",
       "          904865.0                          0.000000e+00   \n",
       "          912895.0                          0.000000e+00   \n",
       "          913198.0                          0.000000e+00   \n",
       "          913550.0                          0.000000e+00   \n",
       "          920639.0                          0.000000e+00   \n",
       "          921671.0                          0.000000e+00   \n",
       "          922102.0                          0.000000e+00   \n",
       "          928972.0                          0.000000e+00   \n",
       "          928976.0                          0.000000e+00   \n",
       "...                                                  ...   \n",
       "72618833  912221658.0                       0.000000e+00   \n",
       "72618841  912221658.0                       0.000000e+00   \n",
       "72618868  912221658.0                       0.000000e+00   \n",
       "72618876  912221658.0                       0.000000e+00   \n",
       "72618884  912221658.0                       0.000000e+00   \n",
       "72618892  912221658.0                       0.000000e+00   \n",
       "72618906  912221658.0                       0.000000e+00   \n",
       "72618914  912221658.0                       0.000000e+00   \n",
       "72618922  897344855.0                      1.364387e-316   \n",
       "72618930  914816462.0                       0.000000e+00   \n",
       "72618949  899778.0                          0.000000e+00   \n",
       "72618957  899778.0                          0.000000e+00   \n",
       "72618965  899778.0                          0.000000e+00   \n",
       "72618973  899778.0                          0.000000e+00   \n",
       "72618981  890167052.0                       0.000000e+00   \n",
       "72619007  1312330.0                         0.000000e+00   \n",
       "72619015  1085817.0                         0.000000e+00   \n",
       "72619023  1001695.0                         0.000000e+00   \n",
       "72619031  922458693.0                       0.000000e+00   \n",
       "72619058  923759476.0                       0.000000e+00   \n",
       "72619066  931021812.0                       0.000000e+00   \n",
       "72619074  931021812.0                       0.000000e+00   \n",
       "72624752  902929364.0                       0.000000e+00   \n",
       "72624760  899336736.0                       0.000000e+00   \n",
       "72624779  872971.0                          0.000000e+00   \n",
       "72626895  904267083.0                       0.000000e+00   \n",
       "72626909  929134788.0                       0.000000e+00   \n",
       "72627301  245384.0                          0.000000e+00   \n",
       "72627328  893632120.0                       0.000000e+00   \n",
       "72627352  929534093.0                       0.000000e+00   \n",
       "\n",
       "                       ratio_operating_result_consolidated_operating_result  \n",
       "id_branch id_company                                                         \n",
       "0         428134.0                                                   NaN     \n",
       "          803351.0                                                   NaN     \n",
       "          810695.0                                                   NaN     \n",
       "          811258.0                                                   NaN     \n",
       "          811333.0                                                   NaN     \n",
       "          818258.0                                                   NaN     \n",
       "          823722.0                                                   NaN     \n",
       "          829630.0                                                   NaN     \n",
       "          834432.0                                                   NaN     \n",
       "          834909.0                                                   NaN     \n",
       "          847212.0                                                   NaN     \n",
       "          853730.0                                                   NaN     \n",
       "          854070.0                                                   NaN     \n",
       "          860012.0                                                   NaN     \n",
       "          867886.0                                                   NaN     \n",
       "          868180.0                                                   NaN     \n",
       "          876537.0                                                   NaN     \n",
       "          885130.0                                                   NaN     \n",
       "          895625.0                                                   NaN     \n",
       "          898359.0                                                   NaN     \n",
       "          899008.0                                                   NaN     \n",
       "          904865.0                                                   NaN     \n",
       "          912895.0                                                   NaN     \n",
       "          913198.0                                                   NaN     \n",
       "          913550.0                                                   NaN     \n",
       "          920639.0                                                   NaN     \n",
       "          921671.0                                                   NaN     \n",
       "          922102.0                                                   NaN     \n",
       "          928972.0                                                   NaN     \n",
       "          928976.0                                                   NaN     \n",
       "...                                                                  ...     \n",
       "72618833  912221658.0                                                NaN     \n",
       "72618841  912221658.0                                                NaN     \n",
       "72618868  912221658.0                                                NaN     \n",
       "72618876  912221658.0                                                NaN     \n",
       "72618884  912221658.0                                                NaN     \n",
       "72618892  912221658.0                                                NaN     \n",
       "72618906  912221658.0                                                NaN     \n",
       "72618914  912221658.0                                                NaN     \n",
       "72618922  897344855.0                                           0.000000     \n",
       "72618930  914816462.0                                                NaN     \n",
       "72618949  899778.0                                                   NaN     \n",
       "72618957  899778.0                                                   NaN     \n",
       "72618965  899778.0                                                   NaN     \n",
       "72618973  899778.0                                                   NaN     \n",
       "72618981  890167052.0                                                inf     \n",
       "72619007  1312330.0                                                  NaN     \n",
       "72619015  1085817.0                                                  NaN     \n",
       "72619023  1001695.0                                                  NaN     \n",
       "72619031  922458693.0                                                NaN     \n",
       "72619058  923759476.0                                                NaN     \n",
       "72619066  931021812.0                                                NaN     \n",
       "72619074  931021812.0                                                NaN     \n",
       "72624752  902929364.0                                                NaN     \n",
       "72624760  899336736.0                                                NaN     \n",
       "72624779  872971.0                                                   NaN     \n",
       "72626895  904267083.0                                                inf     \n",
       "72626909  929134788.0                                                NaN     \n",
       "72627301  245384.0                                                   NaN     \n",
       "72627328  893632120.0                                                NaN     \n",
       "72627352  929534093.0                                                NaN     \n",
       "\n",
       "[1966208 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credit_flags = df.groupby(['id_company', 'id_branch', 'color_credit_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credit_flags.size().unstack(fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SBI groups \n",
      "Done creating SBI groups\n"
     ]
    }
   ],
   "source": [
    "print('Creating SBI groups ')\n",
    "df = create_sbi_groups(df)\n",
    "print('Done creating SBI groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating delta of variables \n",
      "Done calculating delta of variables \n"
     ]
    }
   ],
   "source": [
    "print('Calculating delta of variables ')\n",
    "df = calculate_delta_of_column(df, col_list=['qty_employees','qty_issued_credit_reports', \n",
    "                                                    'score_payment_assessment',\n",
    "                                                   'code_legal_form', 'code_SBI_2_group'])\n",
    "print('Done calculating delta of variables ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating code legal form groups \n",
      "Done creating code legal form groups\n"
     ]
    }
   ],
   "source": [
    "print('Creating code legal form groups ')\n",
    "df = create_code_legal_form_groups(df)\n",
    "print('Done creating code legal form groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ages of variables \n"
     ]
    }
   ],
   "source": [
    "print('Calculating ages of variables ')\n",
    "df = calculate_age_based_on_date(df,['date_established', 'year_consolidated_operating_result', \n",
    "                                     'year_consolidated_revenue',\n",
    "                                    'year_operating_result', 'year_qty_employees', 'year_revenue', 'date_relocation_last'])\n",
    "print('Done calculating ages of variables ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Calculating ratio of columns')\n",
    "df = calculate_ratio_of_column(df, col_list=['amt_operating_result',\n",
    "                                                    'amt_consolidated_operating_result',\n",
    "                                                     'amt_revenue',\n",
    "                                                    'amt_consolidated_revenue'])\n",
    "print('Done calculating ratio of columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Making dummies into counts')\n",
    "df = column_dummies_into_counts(df, col_list=['color_credit_status','rat_pd', 'code_legal_form_group',\n",
    "                                              'code_SBI_2_group'])\n",
    "print('Done making dummies into counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Calculating if any true ')\n",
    "df = calculate_if_any_true(df, col_list=['is_discontinued', 'code_financial_calamity'])\n",
    "print('Done calculating if any true ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Calculating mean of columns ')\n",
    "df = calculate_mean_of_column(df, col_list=['amt_consolidated_operating_result', \n",
    "                                                    'amt_consolidated_revenue',\n",
    "                                                   'amt_operating_result','amt_revenue',\n",
    "                                                   'qty_employees', 'qty_issued_credit_reports',\n",
    "                                                  'score_payment_assessment' , \n",
    "                                                   'score_pd'])\n",
    "print('Done calculating mean of columns ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Calculating sum of columns')\n",
    "df = calculate_sum_of_column(df, col_list=['qty_address_mutations_month',\n",
    "                                                    'qty_started_names',\n",
    "                                                     'qty_stopped_names',\n",
    "                                                    'total_changeof_board_members_']) \n",
    "print('Done calculating sum of columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Calculating variance of columns')\n",
    "df = calculate_variance_of_column(df, col_list=['qty_employees',\n",
    "                                                    'qty_issued_credit_reports',\n",
    "                                                     'score_payment_assessment',\n",
    "                                                    'score_pd']) \n",
    "print('Done calculating variance of columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df.groupby(['id_company', \n",
    "            'id_branch', \n",
    "            'color_credit_status']).size().unstack(fill_value=0).columns = ['qty_flags_green', \n",
    "                                                                            'qty_flags_orange', \n",
    "                                                                            'qty_flags_red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(DataFrame(df).head(5).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dropping old columns')\n",
    "df = drop_old_columns(df, col_list = ['date_established', 'year_consolidated_operating_result', \n",
    "                                      'year_consolidated_revenue', \n",
    "                                      'year_operating_result', 'year_qty_employees', 'year_revenue',\n",
    "                                      'is_discontinued', 'code_financial_calamity', \n",
    "                                      'amt_consolidated_operating_result', 'amt_consolidated_revenue', \n",
    "                                      'amt_operating_result','amt_revenue','qty_employees', \n",
    "                                      'qty_issued_credit_reports', 'score_payment_assessment' ,\n",
    "                                      'score_pd', 'color_credit_status','rat_pd',\n",
    "                                      'qty_address_mutations_month','qty_started_names',\n",
    "                                      'qty_stopped_names', 'total_changeof_board_members_', 'is_sole_proprietor',\n",
    "                                      'code_discontinuation','date_financial_calamity_started', \n",
    "                                      'date_financial_calamity_stopped', 'id_company_creditproxy', \n",
    "                                      'financial_calamity_outcome', 'has_increased_risk' , \n",
    "                                      'perc_credit_limit_adjustment',\n",
    "                                      'date_start', 'from_date_start', 'qty_address_mutations_total',\n",
    "                                      'code_legal_form_group', 'code_SBI_2_group', 'date_relocation_last', \n",
    "                                      'date_relocation_penultimate'])\n",
    "print('Done dropping old columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(' Deduplicating rows of original dataframe')\n",
    "df = deduplicate_rows(df)\n",
    "print(' Done deduplicating rows of original dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Getting target of next year and adding it as a column') \n",
    "df = replace_has_relocated_with_nextyear(df= df, next_year= next_year,\n",
    "                               dir_prefix= '02_cleaned')\n",
    "print('Done getting target of next year and adding it as a column' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(' Cleaning aggregated data frame ')\n",
    "df = clean_after_aggregations(df)\n",
    "print('Done cleaning and aggreating dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Saving DF local to VM into files_to_bucket folder')\n",
    "save_df_locally(df= df, dir_prefix= 'files_to_bucket/aggregated', year = year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "one_year_df = aggregate_full_year(year = '2015', dir_prefix= '02_clean',\n",
    "                                  save_df_locally_flag= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(DataFrame(one_year_df).head(100).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(one_year_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### one_year_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graydon-moving",
   "language": "python",
   "name": "graydon-moving"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
